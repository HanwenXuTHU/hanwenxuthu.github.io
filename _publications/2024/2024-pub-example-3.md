---
title:          "A whole-slide foundation model for digital pathology from real-world data"
date:           2024-05-22 00:01:00 +0800
selected:       true
pub:            "Nature"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">2,000,000 downloads</span>'
pub_date:       "2024"
semantic_scholar_id: 5b3969e0404b96524e03ddbbae6ac10e3357dc75  # use this to retrieve citation count
abstract: >-
  Prov-GigaPath is a large-scale digital pathology foundation model pretrained on 1.3 billion image tiles from 171,189 whole-slide images across 30,000+ patients and 31 tissue types in the Providence network.
  Built on a new GigaPath architecture that adapts LongNet for slide-level learning, it enables ultra-large-context modeling of gigapixel pathology slides.
  Prov-GigaPath achieves state-of-the-art results on 25 of 26 benchmark tasks and demonstrates strong potential for vision–language pathology modeling using real-world data.
cover:          /assets/images/covers/gigapath.png
authors:
  - Hanwen Xu*
  - Naoto Usuyama*
  - Jaspreet Bagga
  - Sheng Zhang
  - Rajesh Rao
  - Tristan Naumann
  - Cliff Wong
  - Zelalem Gero
  - Javier González
  - Yu Gu
  - Yanbo Xu
  - Mu Wei
  - Wenhui Wang
  - Shuming Ma
  - Furu Wei
  - Jianwei Yang
  - Chunyuan Li
  - Jianfeng Gao
  - Jaylen Rosemon
  - Tucker Bower
  - Soohee Lee
  - Roshanthi Weerasinghe
  - Bill J. Wright
  - Ari Robicsek
  - Brian Piening
  - Carlo Bifulco
  - Sheng Wang
  - Hoifung Poon
links:
  Code: https://github.com/prov-gigapath/prov-gigapath
  Model: https://huggingface.co/prov-gigapath/prov-gigapath
  50+ Media Coverage: https://www.forbes.com/sites/saibala/2024/05/22/microsoft-announces-new-foundation-model-for-digital-pathology-diving-deeper-into-clinical-medicine/
---
