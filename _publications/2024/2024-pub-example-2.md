---
title:          "A Multimodal Biomedical Foundation Model Trained from Fifteen Million Imageâ€“Text Pairs"
date:           2024-12-20 00:01:00 +0800
selected:       false
pub:            "The New England Journal of Medicine, AI"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">4,500,000 downloads</span>'
pub_date:       "2024"
semantic_scholar_id: 5814bd146b37e13115af4330caf3a751159a156f  # use this to retrieve citation count
abstract: >-
  We present PMC15M, a dataset of 15 million biomedical image text pairs from 4.4 million articles. Trained on PMC15M, BiomedCLIP achieves state of the art performance across diverse biomedical tasks, even surpassing radiology models like BioViL.
cover:          /assets/images/covers/biomedclip.png
authors:
  - Sheng Zhang*
  - Yanbo Xu*
  - Naoto Usuyama*
  - Hanwen Xu*
  - Jaspreet Bagga
  - Robert Tinn
  - Sam Preston
  - Rajesh Rao
  - Mu Wei
  - Naveen Valluri
  - Cliff Wong
  - Andrea Tupini
  - Yu Wang
  - Matt Mazola
  - Swadheen Shukla
  - Lars Liden
  - Jianfeng Gao
  - Angela Crabtree
  - Brian Piening
  - Carlo Bifulco
  - Matthew P. Lungren
  - Tristan Naumann
  - Sheng Wang
  - Hoifung Poon
links:
  Code: https://github.com/microsoft/BiomedCLIP_data_pipeline
  Model: https://huggingface.co/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blob/main/README.md
---
